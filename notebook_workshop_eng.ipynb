{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melusine + Arta's Workshop\n",
    "\n",
    "## Business Context &#128221;\n",
    "\n",
    "Your are working for an insurance company.\n",
    "\n",
    "Customers are contacting your company for two main reasons:\n",
    "\n",
    "* **Subscriptions:** subscribe, modify or close insurance policies.\n",
    "* **Claims:** initiate or follow the claim process of a covered loss (car, housing, etc).\n",
    "\n",
    "Many employees work on processing client emails through a custom user interface (i.e., a business application).\n",
    "\n",
    "## Data Science Context &#x1F575;\n",
    "\n",
    "You are a Data Scientist in charge of optimizing the email pre-processing (i.e., before being processed by a human).\n",
    "\n",
    "For that purpose your goal is to automatize:\n",
    "\n",
    "* The definition of the *priority* of an email to: `low`, `normal` or `high`.\n",
    "* The categorization of an email into two target business units: `claim` and `contracts`.\n",
    "* The reply in case of a thank you email.\n",
    "\n",
    "Two open-source packages must be used:\n",
    "\n",
    "* [Melusine](https://github.com/MAIF/melusine): Framework for automatic email processing.\n",
    "\n",
    "> Use: create a detection pipeline and use it to identify relevant patterns in the emails.\n",
    "\n",
    "* [Arta](https://github.com/MAIF/arta): A python rules engine\n",
    "\n",
    "> Use: apply rules to translate the detection outputs into clear actions or extra data needed by the business application.\n",
    "\n",
    "\n",
    "First, let's make sure those packages are installed in your *python virtual environment*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'melusine>=3.2' arta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "During this workshop, you will use a demo dataset containing a variety of emails in French and in English.\n",
    "In the first part, you can explore the dataset, then you will use **Melusine** and **Arta** to qualify (i.e., pre-process) the emails.\n",
    "\n",
    "\n",
    "Let's import the dataset and take a sneak peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"workshop_email_data.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melusine: a processing pipeline\n",
    "\n",
    "### Email Preprocessing\n",
    "\n",
    "**Melusine** is a python framework to automatize emails processing.\n",
    "\n",
    "One of the key feature is the default *preprocessing pipeline* which does the following:\n",
    "\n",
    "1. **Cleaning**: remove undesired characters, replace non-breaking spaces, handle specific combinations (ex: \"œ\" => \"oe\").\n",
    "1. **Email Segmentation**: separate an email conversation with mutiple replies and transfers into a list of individual messages.\n",
    "1. **Message Tagging**: tag the different parts of the message (typically to get rid of unwanted footers and signature text).\n",
    "\n",
    "These steps can be edited through configuration files or class inheritance but for the sake of this workshop we will stick with the default preprocessing pipeline.\n",
    "\n",
    "Let's import and run this pipeline on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.pipeline import MelusinePipeline\n",
    "\n",
    "\n",
    "pipe = MelusinePipeline.from_config(\"preprocessing_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = pipe.transform(df)\n",
    "\n",
    "# Look at last columns\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "####  &#x1F449; Your turn &#x1F477;\n",
    "\n",
    "The first email in the DataFrame is composed of two messages (initial message and forwarded message). The raw email string looks like this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(preprocessed_df.iloc[0][\"body\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing pipeline created a new column `messages` which is a list of `Message` objects.\n",
    "Hint 1 : You can use print on a `Message` object for a user-friendly display.\n",
    "Hint 2 : The `extract_parts` and `extract_text` methods can be useful to extract the text of a message.\n",
    "Check out the [Message](https://github.com/MAIF/melusine/blob/master/melusine/message.py) class for more details.\n",
    "\n",
    "Inspect the message corpus:\n",
    "\n",
    "* Print the first and second messages of the first email in the dataset.\n",
    "* Extract the part tagged as \"BODY\" of any message of your choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MelusineRegex\n",
    "\n",
    "The `MelusineRegex` is a convenient class to simplify detections using **regexes**. Main features are:\n",
    "\n",
    "* Name \"regex patterns\" for readable and explainable results.\n",
    "* Easily define patterns to be ignored and patterns that prevent matching (forget complex and unreadable negative look behind mecanisms).\n",
    "* Keep matching and non-matching exemples close to the regex definition to avoid loosing track of what the regex does.\n",
    "\n",
    "We will provide a working regex for this workshop: `EmergencyRegex`. This one will be used later to detect urgent requests in the emails.\n",
    "\n",
    "*N.B: You can check the code of the class [MelusineRegex](https://github.com/MAIF/melusine/blob/29815b578ba852b7c79116a926ef0a0e3bd0e1d5/melusine/base.py#L314), in particular docstrings and methods' type hints.*"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "####  &#x1F449; Your turn &#x1F477;\n",
    "\n",
    "When intantiating the `EmergencyRegex` class, it will be tested against every element of the `match_list` (match expected) and the `no_match_list` (no match expected).\n",
    "An error has been introduced in the regexes, try to find it and correct it.\n",
    "At instantitation, if the test passes, nothing will be displayed, otherwise an error will be raised."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.base import MelusineRegex\n",
    "\n",
    "\n",
    "class EmergencyRegex(MelusineRegex):\n",
    "    \n",
    "    @property\n",
    "    def positive(self):\n",
    "        \"\"\"At least one of these patterns has to match for a global match of the MelusineRegex\"\"\"\n",
    "        return {\n",
    "            \"regex_1\": \"urggen(t|ce)|emergency\",\n",
    "            \"regex_2\": r\"as soon as possible\", \n",
    "            \"regex_3\": r\"(d[èe]s que|le plus vite|aussi vite que) possible\",\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def negative(self):\n",
    "        \"\"\"Any matching pattern will prevent the global match of the MelusineRegex\"\"\"\n",
    "        return r\"urgences\"\n",
    "    \n",
    "    @property\n",
    "    def match_list(self):\n",
    "        \"\"\"Text exemples that MUST be matched by the MelusineRegex\"\"\"\n",
    "        return [\n",
    "            \"C'est urgent\",\n",
    "            \"Ceci est une URGENCE\",\n",
    "            \"Call me as soon as possible\",\n",
    "        ]\n",
    "    \n",
    "    @property\n",
    "    def no_match_list(self):\n",
    "        \"\"\"Text exemples that MUST NOT be matched by the MelusineRegex\"\"\"\n",
    "        return [\n",
    "            \"Je travaille dans le service des urgences\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your new MelusineRegex\n",
    "reg = EmergencyRegex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MelusineDetector\n",
    "\n",
    "Business requests may become more and more complex over time.\n",
    "\n",
    "E.g., \"Could you handle this weird edge case when the email is sent from an autonomous vehicle?\"\n",
    "\n",
    "The objective of the `MelusineDetector` is to standardise how *detections* are performed on emails and restrain the technical debt that occurs during the life of an application.\n",
    "\n",
    "The key elements of a `MelusineDetector` are:\n",
    "\n",
    "1. **Declaration of input and output columns**: missing columns in the input DataFrame can be identified early-on => Keep track of which detector created a column.\n",
    "1. **pre_detect()**: processing to be done prior to detection. Typically assemble the text of interest.\n",
    "1. **detect()**: performed the core detection using regex, machine learning model or heuristics.\n",
    "1. **post_detect()**: combine the detection outputs to product the final detector result.\n",
    "\n",
    "You can find more details in the Melusine documentation on [MelusineDetector tutorials](https://maif.github.io/melusine/tutorials/05a_MelusineDetectors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install unidecode, needed by the detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.base import MelusineDetector\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "class EmergencyDetector(MelusineDetector):\n",
    "    \"\"\"A detector to detect emergency in emails\"\"\"\n",
    "\n",
    "    def __init__(self, name=\"emergency_detector\"):\n",
    "        self.regex = EmergencyRegex()\n",
    "\n",
    "    @property\n",
    "    def input_columns(self):\n",
    "        \"\"\"Input columns required by the detector\"\"\"\n",
    "        return [\"messages\", \"header\"]\n",
    "\n",
    "    @property\n",
    "    def output_columns(self):\n",
    "        \"\"\"Output columns created by the detector\"\"\"\n",
    "        return [\"emergency_detector_result\"]\n",
    "\n",
    "    def pre_detect(self, row, debug_mode=False):\n",
    "        \"\"\"Data transformations prior to the core detection\"\"\"\n",
    "        last_body = row[\"messages\"][0].extract_text(target_tags=[\"BODY\", \"THANKS\"])\n",
    "        row[\"effective_text\"] = row[\"header\"] + \"\\n\" + unidecode(last_body).lower()\n",
    "        return row\n",
    "\n",
    "    def detect(self, row, debug_mode=False):\n",
    "        \"\"\"Core detection method\"\"\"\n",
    "        match_data = self.regex(row[\"effective_text\"])\n",
    "        row[\"emergency_detector_result\"] = match_data[\"match_result\"]\n",
    "        \n",
    "        if debug_mode:\n",
    "            row[self.DEBUG_DICT_COL] = match_data\n",
    "            \n",
    "        return row\n",
    "    \n",
    "    def post_detect(self, row, debug_mode=False):\n",
    "        \"\"\"Data transformations posterior to the core detection\"\"\"\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency_detector = EmergencyDetector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the Detector on an Email Corpus\n",
    "\n",
    "Run the detector on the email corpus and checkout the emergency detector's result (`emergency_detector_result` column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency_df = emergency_detector.transform(preprocessed_df)\n",
    "emergency_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  &#x1F449; Your turn &#x1F477;\n",
    "Now, implement a `ThanksRegex` and integrate it to a `ThanksDetector`.\n",
    "(Replace the `?` with the correct code in both the `ThanksRegex` and `ThanksDetector` classes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ThanksRegex(MelusineRegex):\n",
    "\n",
    "    @property\n",
    "    def positive(self):\n",
    "        return {\n",
    "            \"thanks_fr\": ?,\n",
    "            \"thanks_en\": ?,\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def negative(self):\n",
    "        return {\n",
    "            \"negative_thanks_fr\": ?,\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def match_list(self):\n",
    "        return [\n",
    "            ?\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def no_match_list(self):\n",
    "        return [\n",
    "            ?\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ThanksDetector(MelusineDetector):\n",
    "\n",
    "    def __init__(self, name=\"thanks_detector\"):\n",
    "        self.regex = ?\n",
    "\n",
    "    @property\n",
    "    def input_columns(self):\n",
    "        return [ ? ]\n",
    "\n",
    "    @property\n",
    "    def output_columns(self):\n",
    "        return [ ? ]\n",
    "\n",
    "    def pre_detect(self, row, debug_mode=False):\n",
    "        ?\n",
    "        return row\n",
    "\n",
    "    def detect(self, row, debug_mode=False):\n",
    "        ?\n",
    "\n",
    "        return row\n",
    "\n",
    "    def post_detect(self, row, debug_mode=False):\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thanks_detector = ThanksDetector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, implement a `RoutingRegex` and integrate it to a `RoutingDetector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RoutingRegex(MelusineRegex):\n",
    "\n",
    "    ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RoutingDetector(MelusineDetector):\n",
    "\n",
    "    ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "routing_detector = RoutingDetector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MelusinePipeline\n",
    "\n",
    "The `MelusinePipeline` object (inheriting from the sklearn Pipeline object) lets you assemble all the detectors into a pipeline that can be executed with a simple `transform()` method. It also brings features like:\n",
    "   * input columns check (raises an error if mandatory input columns are missing)\n",
    "   * pipeline load from (YAML) configuration files.\n",
    "\n",
    "Let's assemble the pipeline with the detectors we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.pipeline import MelusinePipeline\n",
    "\n",
    "pipe = MelusinePipeline([\n",
    "    (\"emergency_detector\", emergency_detector),\n",
    "    (\"thanks_detector\", thanks_detector),\n",
    "    (\"routing_detector\", routing_detector),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, let's run the pipeline on our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_transformed = pipe.transform(preprocessed_df)\n",
    "df_transformed.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arta: a rules engine\n",
    "\n",
    "### Use Case\n",
    "\n",
    "Thanks to the previous **Melusine** pipeline, we are able to process emails and get the following extra details:\n",
    "\n",
    "* Is it an urgent email?\n",
    "* Is it about claims or contracts?\n",
    "* Is it a thank you email?\n",
    "\n",
    "But this new data is not enough. Remember, we need to define for each email a *priority* and if we need an *automatic reply* or not.\n",
    "\n",
    "After talking with the people in charge of handling the customers emails, we defined the following business rules:\n",
    "\n",
    "#### Email Priority\n",
    "\n",
    "1. If an email is urgent, regardless of the business unit (claims or contracts), the priority should be set to \"high\".\n",
    "2. If an email is a thank you email for the claims, priority should be set to \"low\".\n",
    "3. Other cases should be set to \"medium\".\n",
    "\n",
    "#### Automatic Reply\n",
    "\n",
    "1. If the email is about contracts and is a thank you email, you should send the automatic reply which id is \"THANK_U_4_YOUR_THANK_U\".\n",
    "2. Do nothing for other cases.\n",
    "\n",
    "\n",
    "**Arta**`s goal is to simplify *rules definition* and *rules execution* in order to produce the expected outputs (priority and automatic reply here).\n",
    "\n",
    "To do that, we simply need to:\n",
    "\n",
    "1. Prepare the input data.\n",
    "1. Define the business rules.\n",
    "1. Implement the needed functions.\n",
    "1. Use the rules engine to apply the rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data\n",
    "\n",
    "In **Arta**, `input_data` is the data fed to the rules engine. In other words, it is the data on which the rules are applied.\n",
    "\n",
    "It must be a [mapping](https://docs.python.org/3/glossary.html#term-mapping) object (i.e., a dictionary like object).\n",
    "\n",
    "This dictionary could be an example:\n",
    "\n",
    "```python\n",
    "input_data = {\n",
    "    \"id\": 42,\n",
    "    \"cleaned_body\": \"Hi, I tried to reach you but unfortunately blah blah...\", \n",
    "    \"business\": \"CLAIM\",\n",
    "    \"emergency\": True, \n",
    "    \"thank_you\": False,\n",
    "}\n",
    "```\n",
    "\n",
    "First, we are going to develop a function that maps the Melusine pipeline's output to the Arta's input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  &#x1F449; Your turn &#x1F477;\n",
    "\n",
    "Implement a function to convert a line (i.e., a `pandas.Series`) of the `DataFrame` referenced in the `processed_df` variable into a python dictionary with the same schema as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(row):\n",
    "    ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "input_data = convert_to_dict(df_transformed.iloc[0])\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Group\n",
    "\n",
    "In **Arta**, a **rule group** is grouping different **rules** with a common output (generally, but not always).\n",
    "\n",
    "In our case, we could define 2 groups:\n",
    "\n",
    "1. `priority`\n",
    "1. `auto_reply`\n",
    "\n",
    "**Rule groups** are made of **rules** and they are bundled into a **rule set**. \n",
    "All of these are defined in a configuration file (i.e., *YAML file*) as you can see in the [documentation](https://maif.github.io/arta/how_to/#rule-set-and-rule-group)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  &#x1F449; Your turn &#x1F477;\n",
    "\n",
    "Define above rules using the following template. You can name the *validation functions* as you want, you will implement them later.\n",
    "\n",
    "*Hint:  use the [standard conditions](https://maif.github.io/arta/how_to/#simple-condition).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "---\n",
    "rules:\n",
    "  default_rule_set:\n",
    "    admission:\n",
    "# Complete below\n",
    "        \n",
    "\n",
    "actions_source_modules:\n",
    "  - assets.actions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your are done, copy and paste these rules into a new YAML file: `./assets/rules.yaml` (file name of your choice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Functions\n",
    "\n",
    "A *rule* is made of *conditions* and one *action*. When conditions are validated (i.e., True) the *action* is executed.\n",
    "\n",
    "In fact, *actions* are just regular python *function* and they are named **action functions**.\n",
    "\n",
    "If you go back to the YAML definition of your rules, you can see:\n",
    "\n",
    "```yaml\n",
    "        action: set_priority\n",
    "        action_parameters:\n",
    "          value: MEDIUM\n",
    "```\n",
    "\n",
    "* `action:` is the name of your action function.\n",
    "* `action_parameters:` are the names and the values of the arguments passed to the function when executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  &#x1F449; Your turn &#x1F477;\n",
    "\n",
    "Look at your rules and list the validation functions that you need to implement:\n",
    "\n",
    "* ...\n",
    "* ...\n",
    "\n",
    "Now, implement them in the following python module `rules/actions.py`. \n",
    "\n",
    "*Hint: look at the following [documentation page](https://maif.github.io/arta/a_simple_example/#actions).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Engine\n",
    "\n",
    "Last but not least, we need to apply the rules on our data, it is the purpose of the rules engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  &#x1F449; Your turn &#x1F477;\n",
    "\n",
    "Instanciate a rules engine and apply the rules on the **Melusine** pipeline results for one email.\n",
    "\n",
    "*Hint: [Usage documentation](https://maif.github.io/arta/how_to/#usage).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  &#x1F449; Your turn &#x1F477;\n",
    "\n",
    "Apply on all emails and print their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compare the obtained results with expected ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End\n",
    "\n",
    "Now we can feed the employee business application with the emails and the needed extra informations. Automatic replies and prioritization will speed up the email processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
